# https://taskfile.dev

version: "3"

vars:
  REPOSITORY: ghcr.io/adrianliechti/llama-platform
  #REPOSITORY: ghcr.io/adrianliechti/llama-platform:nightly

includes:
  llama:
    taskfile: ./Taskfile.llama.yml
  
  nomic:
    taskfile: ./Taskfile.nomic.yml
  
  reranker:
    taskfile: ./Taskfile.reranker.yml
  
  whisper:
    taskfile: ./Taskfile.whisper.yml
  
  tts:
    taskfile: ./Taskfile.tts.yml
  
  unstructured:
    taskfile: ./Taskfile.unstructured.yml

  qdrant:
    taskfile: ./Taskfile.qdrant.yml

tasks:
  publish:
    cmds:
      - docker buildx build . --push --platform linux/amd64,linux/arm64 --tag {{.REPOSITORY}}

  server:
    dotenv: ['.env' ]
    
    cmds:
      - go run cmd/server/main.go

  client:
    cmds:
      - go run cmd/client/main.go

  webui:
    cmds:
      - docker run -it --rm --pull always -p 8000:8000 -e OPENAI_BASE_URL=http://host.docker.internal:8080/v1 ghcr.io/adrianliechti/llama-chat
  
  start:
    cmds:
      - docker run --name llama-platform -d --rm --pull always -p 8080:8080 --env-file .env -v ./config.yaml:/config.yaml -v ./prompts:/prompts ghcr.io/adrianliechti/llama-platform

  stop:
    cmds:
      -  docker rm llama-platform -f
services:
  llama:
    image: ghcr.io/ggerganov/llama.cpp:full
    pull_policy: always
    command: --server --host 0.0.0.0 --port 8000 --path /public --model /models/llama-2-7b-chat.Q4_K_M.gguf --embedding --alias default
    volumes:
      - ./models:/models:cached

  openai:
    image: adrianliechti/llama-openai
    pull_policy: always
    environment:
      - LLAMA_URL=http://llama:8000
    ports:
      - 8080:8080
  
  web:
    image: ghcr.io/mckaywrigley/chatbot-ui:main
    pull_policy: always
    ports:
      - 3000:3000
    environment:
      - OPENAI_API_KEY=changeme
      - OPENAI_API_HOST=http://openai:8080
      - DEFAULT_MODEL=default
# Local Chat using LangChain

## Run Example

- [Ollama](https://ollama.ai)
- [Docker Desktop](https://www.docker.com/products/docker-desktop/)

Start Ollama Server

```shell
$ ollama start
```

Download [Mistral](https://mistral.ai) Model

```shell
$ ollama pull mistral
```

Start Example Application

```shell
docker compose up
```

## Open Jupyter UI

```shell
$ open http://localhost:8888
```
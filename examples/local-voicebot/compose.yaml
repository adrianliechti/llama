services:
  platform:
    image: ghcr.io/adrianliechti/llama-platform
    pull_policy: always
    build:
      context: ../../
      dockerfile: Dockerfile
    ports:
      - 8080:8080
    configs:
      - source: platform
        target: /config.yaml
  
configs:
  platform:
    content: |
      providers:
        - type: llama
          url: http://host.docker.internal:9081
          models:
            mistral-7b-instruct:
              id: mistral-7b-instruct-v0.2.Q4_K_M.gguf

        - type: whisper
          url: http://host.docker.internal:9085
          models:
            whisper-1:
              id: whisper-ggml-medium.bin
        
        - type: mimic
          url: http://host.docker.internal:59125
          models:
            tts-1:
              id: mimic-3
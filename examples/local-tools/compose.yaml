version: "3"

services:
  platform:
    image: adrianliechti/llama-platform
    pull_policy: always
    ports:
      - 8080:8080
    configs:
      - source: config
        target: /config.yaml
  
configs:
  config:
    content: |
      providers:
        - type: ollama
          url: http://host.docker.internal:11434
          models:
            mistral-7b-instruct:
              id: mistral

      chains:
        mistral-fn:
          type: react
          model: mistral-7b-instruct
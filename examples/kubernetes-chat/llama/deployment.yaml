apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama
spec:
  replicas: 1
  revisionHistoryLimit: 0
  strategy:
    type: Recreate
  template:
    spec:
      containers:
        - name: server
          image: ghcr.io/ggerganov/llama.cpp:server
          imagePullPolicy: Always
          args:
            - "--host"
            - "0.0.0.0"
            - "--port"
            - "8080"
            - "--log-disable"
            - "--model"
            - "/models/llama-3-8b-instruct.gguf"
            - "--ctx-size"
            - "8192"
            - "--hf-repo"
            - "NousResearch/Meta-Llama-3-8B-Instruct-GGUF"
            - "--hf-file"
            - "Meta-Llama-3-8B-Instruct-Q5_K_M.gguf"
          ports:
            - containerPort: 8080
          volumeMounts:
            - name: data
              subPath: models
              mountPath: "/models"
          resources: {}
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: llama-data

services:
  platform:
    image: ghcr.io/adrianliechti/llama-platform
    pull_policy: always
    build:
      context: ../../
      dockerfile: Dockerfile
    ports:
      - 8080:8080
    configs:
      - source: platform
        target: /config.yaml
  
  searxng:
    image: searxng/searxng
    pull_policy: always

    environment:
      - SEARXNG_SECRET=ada2c861-33dc-4a0d-ac22-25b61fc1d107

    configs:
      - source: searxng
        target: /etc/searxng/settings.yml
  
  web:
    image: ghcr.io/adrianliechti/llama-streamlit
    pull_policy: always
    ports:
      - 8501:8501
    environment:
      - OPENAI_BASE_URL=http://platform:8080/v1
    depends_on:
      - platform
  
configs:
  platform:
    content: |
      providers:
        - type: ollama
          url: http://host.docker.internal:11434

          models:
            llama:
              id: llama3.1:latest
      
      tools:
        searxng:
          type: searxng
          url: http://searxng:8080
      
      chains:  
        search:
          type: agent
          model: llama
          tools:
            - searxng
  
  searxng:
    file: ./searxng.yaml
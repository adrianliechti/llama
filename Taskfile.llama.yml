# https://taskfile.dev

version: "3"

tasks:
  server:
    deps: [ download-model ]
    cmds:
      - llama-server 
        --port 9081
        --log-disable
        --model ./models/phi-3.1-mini-4k-instruct.gguf 
  
  download-model:
    cmds:
      - mkdir -p models
      - curl -s -L -o models/phi-3.1-mini-4k-instruct.gguf https://huggingface.co/bartowski/Phi-3.1-mini-4k-instruct-GGUF/resolve/main/Phi-3.1-mini-4k-instruct-Q4_K_M.gguf?download=true

    status:
      - test -f models/phi-3.1-mini-4k-instruct.gguf 
  
  test:
    cmds:
      - |
        curl http://localhost:8080/v1/chat/completions \
          -H "Content-Type: application/json" \
          -d '{
            "model": "phi-3.1-mini-4k-instruct",
            "messages": [
              {
                "role": "user",
                 "content": "Hello!"
              }
            ]
          }'
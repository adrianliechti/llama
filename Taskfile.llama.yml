# https://taskfile.dev

version: "3"

tasks:
  server:
    deps: [download-server, download-model]
    cmds:
      - bin/llama-server --port 9081 --log-disable --ctx-size 8192 --model ./models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

  download-model:
    cmds:
      - mkdir -p models
      - curl -s -L -o models/mistral-7b-instruct-v0.2.Q4_K_M.gguf https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q4_K_M.gguf

    status:
      - test -f models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

  download-server:
    cmds:
      - mkdir -p bin
      - rm -rf tmp/llama.cpp
      - git clone https://github.com/ggerganov/llama.cpp tmp/llama.cpp
      - make -C tmp/llama.cpp/
      - cp tmp/llama.cpp/server bin/llama-server
      - cp tmp/llama.cpp/ggml-metal.metal bin/ggml-metal.metal
      - rm -rf tmp/llama.cpp
      - rm -rf tmp

    status:
      - test -f bin/llama-server